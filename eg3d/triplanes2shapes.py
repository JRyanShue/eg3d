
'''
From a dataset of triplanes (presumably generated by our diffusion model), use the EG3D decoder to
create the corresponding directory of 3D shapes.

No rendering required -- we are testing 3D/4D (first just 3D) capabilities of our model.
'''

'''
Ex:

CUDA_VISIBLE_DEVICES=6 python triplanes2shapes.py --triplane_dir=triplanes_to_convert --out_dir=converted_shapes
'''

import os

import blobfile as bf
import click
import dnnlib
import numpy as np
import torch
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm

import legacy
from torch_utils import misc
from training.triplane import TriPlaneGenerator
from .gen_samples import create_samples



#----------------------------------------------------------------------------

'''
Dataset utils adapted from OpenAI "Diffusion Models Beat GANs on Image Synthesis"
'''

class TriplaneDataset(Dataset):
    def __init__(
        self,
        image_paths,
        classes=None,
        shard=0,
        num_shards=1,
    ):
        super().__init__()
        self.local_images = image_paths[shard:][::num_shards]
        self.local_classes = None if classes is None else classes[shard:][::num_shards]

    def __len__(self):
        return len(self.local_images)

    def __getitem__(self, idx):
        path = self.local_images[idx]

        # Get the triplane's saved index for easy reference.
        triplane_idx = int(os.path.basename(path).split('.')[0])

        arr = np.load(path)

        arr = arr.astype(np.float32)  # / 127.5 - 1  <-- need to normalize the triplanes in their own way.
        arr = arr.reshape([-1, arr.shape[-2], arr.shape[-1]])

        return triplane_idx, arr


def _list_image_files_recursively(data_dir):
    results = []
    for entry in sorted(bf.listdir(data_dir)):
        full_path = bf.join(data_dir, entry)
        ext = entry.split(".")[-1]
        if "." in entry and ext.lower() in ["jpg", "jpeg", "png", "gif", "npy"]:
            results.append(full_path)
        elif bf.isdir(full_path):
            results.extend(_list_image_files_recursively(full_path))
    return results

#----------------------------------------------------------------------------


@click.command()
@click.option('--network', 'network_pkl', help='Network pickle filename', required=True)
@click.option('--trunc', 'truncation_psi', type=float, help='Truncation psi', default=1, show_default=True)
@click.option('--trunc-cutoff', 'truncation_cutoff', type=int, help='Truncation cutoff', default=14, show_default=True)
@click.option('--triplane_dir', help='Directory of triplanes to convert to shapes', required=True)
@click.option('--outdir', help='Directory to put completed shapes', required=True)
@click.option('--shape-res', help='', type=int, required=False, metavar='int', default=512, show_default=True)
@click.option('--reload_modules', help='Overload persistent modules?', type=bool, required=False, metavar='BOOL', default=True, show_default=True)
def convert_triplanes(
    network_pkl: str,
    truncation_psi: float,
    truncation_cutoff: int,
    triplane_dir: str,
    outdir: str,
    shape_res: int,
    reload_modules: bool,
):

    shape_format = '.ply'  # Temporary - produces smoother results

    # Load pickled network
    print('Loading networks from "%s"...' % network_pkl)
    device = torch.device('cuda')
    with dnnlib.util.open_url(network_pkl) as f:
        G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore

    # Specify reload_modules=True if you want code modifications to take effect; otherwise uses pickled code
    if reload_modules:
        print("Reloading Modules!")
        G_new = TriPlaneGenerator(*G.init_args, **G.init_kwargs).eval().requires_grad_(False).to(device)
        misc.copy_params_and_buffers(G, G_new, require_all=True)
        G_new.neural_rendering_resolution = G.neural_rendering_resolution
        G_new.rendering_kwargs = G.rendering_kwargs
        G = G_new

    # Create triplane dataset
    all_files = _list_image_files_recursively(triplane_dir)
    triplane_ds = TriplaneDataset(all_files)

    os.makedirs(outdir, exist_ok=True)
    print(f'Converting {len(triplane_ds)} triplanes in \"{triplane_dir}\" to shapes in \"{outdir}\"...')

    # Loop through the triplane directory, converting each triplane into a shape in the outdir
    for triplane_idx, triplane in triplane_ds:  # Loop through triplane data

        # extract a shape.mrc with marching cubes. You can view the .mrc file using ChimeraX from UCSF.
        max_batch=1000000

        samples, voxel_origin, voxel_size = create_samples(N=shape_res, voxel_origin=[0, 0, 0], cube_length=G.rendering_kwargs['box_warp'] * 1)#.reshape(1, -1, 3)
        samples = samples.to(device)
        sigmas = torch.zeros((samples.shape[0], samples.shape[1], 1), device=device)
        transformed_ray_directions_expanded = torch.zeros((samples.shape[0], max_batch, 3), device=device)
        transformed_ray_directions_expanded[..., -1] = -1

        head = 0
        with tqdm(total = samples.shape[1]) as pbar:
            with torch.no_grad():
                while head < samples.shape[1]:
                    torch.manual_seed(0)
                    # Get object densities using pregenerated triplane
                    sigma = G.sample(samples[:, head:head+max_batch], transformed_ray_directions_expanded[:, :samples.shape[1]-head], planes=triplane, truncation_psi=truncation_psi, truncation_cutoff=truncation_cutoff, noise_mode='const')['sigma']
                    sigmas[:, head:head+max_batch] = sigma
                    head += max_batch
                    pbar.update(max_batch)

        sigmas = sigmas.reshape((shape_res, shape_res, shape_res)).cpu().numpy()
        sigmas = np.flip(sigmas, 0)

        # Trim the border of the extracted cube
        pad = int(30 * shape_res / 256)
        pad_value = -1000
        sigmas[:pad] = pad_value
        sigmas[-pad:] = pad_value
        sigmas[:, :pad] = pad_value
        sigmas[:, -pad:] = pad_value
        sigmas[:, :, :pad] = pad_value
        sigmas[:, :, -pad:] = pad_value

        if shape_format == '.ply':
            from shape_utils import convert_sdf_samples_to_ply
            convert_sdf_samples_to_ply(np.transpose(sigmas, (2, 1, 0)), [0, 0, 0], 1, os.path.join(outdir, f'triplane{triplane_idx:04d}.ply'), level=10)
        # elif shape_format == '.mrc': # output mrc
        #     with mrcfile.new_mmap(os.path.join(outdir, f'seed{seed:04d}.mrc'), overwrite=True, shape=sigmas.shape, mrc_mode=2) as mrc:
        #         mrc.data[:] = sigmas


#----------------------------------------------------------------------------

if __name__ == "__main__":
    convert_triplanes()

#----------------------------------------------------------------------------

